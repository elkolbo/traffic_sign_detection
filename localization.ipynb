{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pathlib' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\loren\\Documents\\AI_BME\\traffic\\localization.ipynb Cell 2\u001b[0m line \u001b[0;36m<cell line: 18>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/loren/Documents/AI_BME/traffic/localization.ipynb#W1sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     bboxes \u001b[39m=\u001b[39m [\u001b[39mint\u001b[39m(value \u001b[39m*\u001b[39m image_width) \u001b[39mfor\u001b[39;00m value \u001b[39min\u001b[39;00m bboxes]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/loren/Documents/AI_BME/traffic/localization.ipynb#W1sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m bboxes\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/loren/Documents/AI_BME/traffic/localization.ipynb#W1sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m train_label_directory \u001b[39m=\u001b[39m pathlib\u001b[39m.\u001b[39mPath(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/loren/Documents/AI_BME/traffic/localization.ipynb#W1sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mC:\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mUsers\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mloren\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mDocuments\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mAI_BME\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mtraffic\u001b[39m\u001b[39m\\\u001b[39m\u001b[39marchive\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mTrafficSignLocalizationandDetection\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/loren/Documents/AI_BME/traffic/localization.ipynb#W1sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/loren/Documents/AI_BME/traffic/localization.ipynb#W1sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m val_label_directory \u001b[39m=\u001b[39m pathlib\u001b[39m.\u001b[39mPath(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/loren/Documents/AI_BME/traffic/localization.ipynb#W1sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mC:\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mUsers\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mloren\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mDocuments\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mAI_BME\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mtraffic\u001b[39m\u001b[39m\\\u001b[39m\u001b[39marchive\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mTrafficSignLocalizationandDetection\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mvalid\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/loren/Documents/AI_BME/traffic/localization.ipynb#W1sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/loren/Documents/AI_BME/traffic/localization.ipynb#W1sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m train_labelpaths \u001b[39m=\u001b[39m train_label_directory\u001b[39m.\u001b[39mglob(\u001b[39m\"\u001b[39m\u001b[39m*.txt\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pathlib' is not defined"
     ]
    }
   ],
   "source": [
    "def yolo2coco(image_width, bboxes):\n",
    "    \"\"\"\n",
    "    convert yolo annottion to coco annottion for easier usage with keras\n",
    "    yolo => [xmid, ymid, w, h] (normalized)\n",
    "    coco => [xmin, ymin, w, h]\n",
    "\n",
    "    \"\"\"\n",
    "    # conversion (xmid, ymid) => (xmin, ymin)\n",
    "    bboxes[0] = bboxes[0] - bboxes[2] * 0.5\n",
    "    bboxes[1] = bboxes[1] - bboxes[3] * 0.5\n",
    "\n",
    "    # denormalizing\n",
    "    bboxes = [int(value * image_width) for value in bboxes]\n",
    "\n",
    "    return bboxes\n",
    "\n",
    "\n",
    "train_label_directory = pathlib.Path(\n",
    "    r\"C:\\Users\\loren\\Documents\\AI_BME\\traffic\\archive\\TrafficSignLocalizationandDetection\\train\\labels\"\n",
    ")\n",
    "val_label_directory = pathlib.Path(\n",
    "    r\"C:\\Users\\loren\\Documents\\AI_BME\\traffic\\archive\\TrafficSignLocalizationandDetection\\valid\\labels\"\n",
    ")\n",
    "\n",
    "train_labelpaths = train_label_directory.glob(\"*.txt\")\n",
    "val_lablepaths = val_label_directory.glob(\"*.txt\")\n",
    "\n",
    "\n",
    "# load all labels from disk into a list\n",
    "def get_labels(labelpaths):\n",
    "    labels = []\n",
    "    for path in labelpaths:\n",
    "        with open(path) as txt_file:\n",
    "            label = txt_file.readlines()\n",
    "            label = label[0].split(\" \")\n",
    "            label = [float(x) for x in label]\n",
    "            label = yolo2coco(416, label[1:])\n",
    "            labels.append(label)\n",
    "    return labels\n",
    "\n",
    "\n",
    "train_labels = get_labels(train_labelpaths)\n",
    "val_labels = get_labels(val_lablepaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1392 images belonging to 1 classes.\n",
      "Found 173 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "\n",
    "# Define the paths to your image directory and annotations\n",
    "train_directory = \"C:/Users/loren\\Documents/AI_BME/traffic/archive/TrafficSignLocalizationandDetection/train/images\"\n",
    "val_directory = \"C:/Users/loren\\Documents/AI_BME/traffic/archive/TrafficSignLocalizationandDetection/valid/images\"\n",
    "\n",
    "# Load and preprocess the images\n",
    "datagen = ImageDataGenerator(rescale=1.0 / 255)  # You can customize this\n",
    "\n",
    "# Define a generator for images and labels\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    train_directory,\n",
    "    class_mode=None,  # No class labels, we'll use bounding box annotations\n",
    "    target_size=(416, 416),  # Specify image dimensions\n",
    "    batch_size=1,\n",
    ")\n",
    "\n",
    "val_generator = datagen.flow_from_directory(\n",
    "    val_directory,\n",
    "    class_mode=None,  # No class labels, we'll use bounding box annotations\n",
    "    target_size=(416, 416),  # Specify image dimensions\n",
    "    batch_size=1,\n",
    ")\n",
    "\n",
    "\n",
    "# Create a list of all images\n",
    "def create_dataset(image_generator):\n",
    "    images = []\n",
    "    for i in range(len(image_generator)):\n",
    "        image = np.array(image_generator[i].reshape(416, 416, 3))\n",
    "        images.append((image))\n",
    "    return images\n",
    "\n",
    "\n",
    "# Create the dataset\n",
    "train_images = create_dataset(train_generator)\n",
    "val_images = create_dataset(val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.metrics import MeanIoU\n",
    "\n",
    "\n",
    "# Define your SSD model\n",
    "def create_ssd_model(input_shape, num_classes):\n",
    "    base_model = VGG16(weights=\"imagenet\", include_top=False, input_shape=input_shape)\n",
    "    x = base_model.layers[-5].output\n",
    "    x = layers.Conv2D(1024, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(512, activation=\"relu\")(x)\n",
    "    predictions = layers.Dense(num_classes, activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = models.Model(inputs=base_model.input, outputs=predictions)\n",
    "    return model\n",
    "\n",
    "\n",
    "# Create the SSD model\n",
    "input_shape = (416, 416, 3)  # Adjust to your image size\n",
    "num_classes = 4  # Modify to the number of classes or bounding box parameters\n",
    "ssd_model = create_ssd_model(input_shape, num_classes)\n",
    "\n",
    "# Compile the model\n",
    "ssd_model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001), loss=MeanSquaredError(), metrics=[\"mae\", \"mse\"]\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "# Define your training data and labels, and use model.fit() to train the model\n",
    "# Make sure your training data includes bounding box coordinates as labels\n",
    "# You might need to preprocess the labels to convert them to an appropriate format\n",
    "# Example: [(image1, [x1, y1, x2, y2]), (image2, [x1, y1, x2, y2]), ...]\n",
    "# Modify batch size, epochs, and other training settings as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32  # Adjust as needed\n",
    "epochs = 50  # Adjust as needed\n",
    "\n",
    "\n",
    "def preprocess_image(image, bbox):\n",
    "    if np.shape(image) != (416, 416, 3) or np.shape(bbox) != (4,):\n",
    "        print(np.shape(image))\n",
    "        print(np.shape(bbox))\n",
    "    return image, bbox\n",
    "\n",
    "\n",
    "# Apply the preprocessing function to the dataset\n",
    "# dataset_keras = [tuple(preprocess_image(image, bbox)) for image, bbox in dataset]\n",
    "\n",
    "# Create train and validation dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (train_images[:10], train_labels[:10])\n",
    ")\n",
    "train_dataset = train_dataset.batch(batch_size)\n",
    "train_dataset = train_dataset.shuffle(5)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((train_images[:10], train_labels[:10]))\n",
    "val_dataset = val_dataset.batch(batch_size)\n",
    "val_dataset = val_dataset.shuffle(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1/1 [==============================] - 98s 98s/step - loss: 23090.4668 - mae: 136.6620 - mse: 23090.4668 - val_loss: 22955.1250 - val_mae: 136.1750 - val_mse: 22955.1250\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 84s 84s/step - loss: 22955.1250 - mae: 136.1750 - mse: 22955.1250 - val_loss: 22955.1250 - val_mae: 136.1750 - val_mse: 22955.1250\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 64s 64s/step - loss: 22955.1250 - mae: 136.1750 - mse: 22955.1250 - val_loss: 22955.1250 - val_mae: 136.1750 - val_mse: 22955.1250\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 55s 55s/step - loss: 22955.1250 - mae: 136.1750 - mse: 22955.1250 - val_loss: 22955.1250 - val_mae: 136.1750 - val_mse: 22955.1250\n",
      "Epoch 5/50\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "ssd_model.fit(\n",
    "    train_dataset,  # Training labels (bounding box coordinates)\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=val_dataset,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "i2dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
